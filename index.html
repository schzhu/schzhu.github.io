<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <!-- 
        Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, 
        otherwise my analytics will track your page 
    -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script type="text/javascript" async src="./index_files/analytics.js.download"></script>
    <script async src="./index_files/js"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'UA-7580334-2');
    </script>

    <title>Sicheng Zhu</title>

    <meta name="author" content="Sicheng Zhu">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="./index_files/stylesheet.css">
    <link rel="icon" type="image/png" href="./images/icon.png">
    <link rel="stylesheet" href="../../../../AppData/Local/Temp/stylesheet.css">
</head>

<body>
    <table style="width:100%; max-width:900px; padding-top:20px; border:0; border-spacing:0; border-collapse:separate; margin: 0 auto;">
        <tbody>
            <tr>
                <td>
                    <!-- Header Section -->
                    <p align="center" style="margin-bottom:-10px;">
                        <name>Sicheng Zhu</name>
                    </p>
                    <p align="center" style="margin-bottom:0;">
                        <span style="margin-right: 30px;">&#9993; <a href="mailto:sczhu@umd.edu">sczhu@umd.edu</a></span>
                        <a href="https://scholar.google.com/citations?hl=en&user=WdTVEcMAAAAJ" target="_blank">
                            <img src="images/google-scholar.svg" alt="Google Scholar Icon" style="width:20px; height:20px; vertical-align:middle;"> Google Scholar
                        </a>
                        <a href="https://twitter.com/sichengzhuml" target="_blank" style="margin-left: 30px;">
                            <img src="images/twitter-icon.svg" alt="Twitter Icon" style="width:20px; height:20px; vertical-align:middle;"> Twitter
                        </a>
                    </p>

                    <img src="./images/sichengzhu_b.jpg" width="22%" alt="Sicheng Zhu" style="border-radius:10px; float: right; margin-left: 20px; margin-bottom: 20px; margin-top: 22px;">

                    <!-- About Me Section -->
                    <p>
                        I am a fifth-year Ph.D. candidate in the <a href="https://www.cs.umd.edu/">Computer Science Department</a> at the 
                        <a href="http://www.umd.edu/">University of Maryland, College Park</a>, advised by Prof. 
                        <a href="http://furong-huang.com/">Furong Huang</a>. Iâ€™ve interned at Meta GenAI and FAIR, Adobe Research, and Bosch AI center. I expect to graduate in 2025!
                    </p>

                    <!-- Research Interest Section -->
                    <heading style="display: block; margin-top: 30px;"><b>Research Interest</b></heading>
                    <p>
                        <b>GenAI:</b> LLM safety, reasoning, alignment, controllable generation, agent, MLLM
                        <b>Trustworthy machine learning:</b> robustness, generalization, equivariance
                    </p>
<!--                     <p>
                        My goal is to build <b>trustworthy machine learning</b> models.
                    </p>
                    <p>
                        When you are sitting in a self-driving car controlled by such a machine learning
                        model, you know it can recognize trucks because it can identify the wheels, body,
                        and cab that make up the truck, and it can recognize the wheels because it notices
                        contours, tire materials, and hubs (<b>interpretability</b>). It can identify trucks
                        at various angles, lighting conditions, and even under adversarial stickers (<b>robustness</b>).
                        It can also recognize a wide variety of trucks, from heavy trailers to Cybertrucks (<b>generalization</b>).
                        Therefore, you can confidently hand over the steering wheel to it and take a nap on
                        your way to work without worrying about it 
                        <a href="https://www.forbes.com/sites/bradtempleton/2020/06/02/tesla-in-taiwan-crashes-directly-into-overturned-truck-ignores-pedestrian-with-autopilot-on/?sh=3d4ec39758e5" target="_blank">inexplicably
                        crashing into an overturned white truck</a>.
                    </p>
                    <p>
                        My approach to achieving this goal is by endowing machines with common sense about
                        the physical world, with a current focus on modeling the symmetries of objects under
                        various changes that could potentially reduce the learning complexity. For example,
                        when applying angle transformations, material changes, or some pattern changes on a
                        wheel in an image, it still appears as a wheel to humans and maintains its function.
                        My current work aims at incorporating these symmetries into the model.
                    </p> -->

                    <!-- Bio Section -->
                    <heading style="display: block; margin-top: 30px;"><b>Bio</b></heading>
                    <p>
                        Previously, I was a visiting scholar at the <a href="https://www.virginia.edu/">University
                        of Virginia</a> where I was fortunate to be advised by Prof. 
                        <a href="http://www.cs.virginia.edu/~evans/">David Evans</a>. I received my M.E.
                        from <a href="http://english.cas.cn/">Institute of Electronics, Chinese Academy of
                        Sciences</a> and B.S. from <a href="http://en.uestc.edu.cn/">University of
                        Electronic Science and Technology of China</a>.
                    </p>


                    <!-- Publications Section -->
                    <heading style="display: block; margin-top: 30px; margin-bottom: 20px;"><b>Publications - LLM safety and controllable generation</b></heading>
                    <table style="margin-top: 20px;" width="100%">
                        <tbody>

                            <tr>
                                <td valign="top" width="95%" style="padding-bottom: 20px;">
                                    <papertitle>AdvPrefix: An Objective for Nuanced LLM Jailbreaks</papertitle>
                                    <br>
                                    <b>Sicheng Zhu</b>, Brandon Amos, Yuandong Tian, Chuan Guo, Ivan Evtimov
                                    <br>
                                    <em>arXiv 2412.10321</em>
                                    [<a href="https://arxiv.org/abs/2412.10321" target="_blank">arXiv</a>]
                                    [<a href="https://github.com/facebookresearch/jailbreak-objectives">Code</a>]
                                </td>
                            </tr>

                            <tr>
                                <td valign="top" width="95%" style="padding-bottom: 20px;">
                                    <papertitle>GenARM: Reward Guided Generation with Autoregressive Reward Model for Test-time Alignment</papertitle>
                                    <br>
                                    Yuancheng Xu, Udari Madhushani Sehwag, Alec Koppel, <b>Sicheng Zhu</b>, Bang An, Furong Huang, Sumitra Ganesh
                                    <br>
                                    <em>ICLR 2025</em>
                                    [<a href="https://openreview.net/pdf?id=J0qTpmbSbh">Proceedings</a>]
                                    [<a href="https://arxiv.org/abs/2410.08193" target="_blank">arXiv</a>]
                                </td>
                            </tr>

                            <tr>
                                <td valign="top" width="95%" style="padding-bottom: 20px;">
                                    <papertitle>Automatic Pseudo-Harmful Prompt Generation for Evaluating False Refusals in Large Language Models</papertitle>
                                    <br>
                                    Bang An*, <b>Sicheng Zhu*</b>, Ruiyi Zhang, Michael-Andrei Panaitescu-Liess, Yuancheng Xu, Furong Huang
                                    <br>
                                    <em>COLM 2024</em>
                                    [<a href="https://openreview.net/pdf?id=ljFgX6A8NL">Proceedings</a>]
                                    [<a href="https://arxiv.org/abs/2409.00598" target="_blank">arXiv</a>]
                                    [<a href="https://phtest-frf.github.io/">Website</a>]
                                    [<a href="https://github.com/umd-huang-lab/FalseRefusal">Code</a>]
                                    [<a href="https://huggingface.co/datasets/furonghuang-lab/PHTest">Dataset</a>]
                                </td>
                            </tr>

                            <tr>
                                <td valign="top" width="95%" style="padding-bottom: 20px;">
                                    <papertitle>AutoDAN: Interpretable Gradient-Based Adversarial Attacks on Large Language Models</papertitle>
                                    <br>
                                    <b>Sicheng Zhu</b>,
                                    Ruiyi Zhang,
                                    Bang An,
                                    Gang Wu,
                                    Joe Barrow,
                                    Zichao Wang,
                                    Furong Huang,
                                    Ani Nenkova,
                                    Tong Sun
                                    <br>
                                    <em>COLM 2024</em>
                                    [<a href="https://openreview.net/pdf?id=INivcBeIDK">Proceedings</a>]
                                    [<a href="https://arxiv.org/abs/2310.15140" target="_blank">arXiv</a>]
                                    <!-- [<a href="https://autodan-jailbreak.github.io/" target="_blank">Webpage</a>] -->
                                    [<a href="https://github.com/rotaryhammer/code-autodan" target="_blank">Unofficial Code</a>]
                                    [<a href="https://www.snexplores.org/article/chatbot-jailbreaks-bad-ai">Media Coverage</a>]
                                </td>
                            </tr>

                        </tbody>
                    </table>

                    <!-- Publications Section -->
                    <heading style="display: block; margin-top: 30px; margin-bottom: 20px;"><b>Publications - Copyright</b></heading>
                    <table style="margin-top: 20px;" width="100%">
                        <tbody>

                            <tr>
                                <td valign="top" width="95%" style="padding-bottom: 20px;">
                                    <papertitle>PoisonedParrot: Subtle Data Poisoning Attacks to Elicit Copyright-Infringing Content from Large Language Models</papertitle>
                                    <br>
                                    Michael-Andrei Panaitescu-Liess, Pankayaraj Pathmanathan, Yigitcan Kaya, Zora Che, Bang An, <b>Sicheng Zhu</b>, Aakriti Agrawal, Furong Huang
                                    <br>
                                    <em>NAACL 2025</em>
                                    [<a href="https://openreview.net/forum?id=ZXgvPANlwe" target="_blank">OpenReview</a>]
                                </td>
                            </tr>

                            <tr>
                                <td valign="top" width="95%" style="padding-bottom: 20px;">
                                    <papertitle>Can Watermarking Large Language Models Prevent Copyrighted Text Generation and Hide Training Data?</papertitle>
                                    <br>
                                    Michael-Andrei Panaitescu-Liess, Zora Che, Bang An, Yuancheng Xu, Pankayaraj Pathmanathan, Souradip Chakraborty, <b>Sicheng Zhu</b>, Tom Goldstein, Furong Huang
                                    <br>
                                    <em>NeurIPS 2024 AdvML-Frontiers Workshop</em> [<a href="https://advml-frontier.github.io/" target="_blank">Best Paper Award</a>]
                                    <br>
                                    <em>AAAI 2025</em>
                                    [<a href="https://arxiv.org/abs/2407.17417" target="_blank">arXiv</a>]
                                </td>
                            </tr>

                            <tr>
                                <td valign="top" width="95%" style="padding-bottom: 20px;">
                                    <papertitle>Benchmarking the Robustness of Image Watermarks</papertitle>
                                    <br>
                                    Bang An, Mucong Ding, Tahseen Rabbani, Aakriti Agrawal, Yuancheng Xu, Chenghao Deng, 
                                    <b>Sicheng Zhu</b>, Abdirisak Mohamed, Yuxin Wen, Tom Goldstein, Furong Huang
                                    <br>
                                    <em>ICML 2024</em>
                                    [<a href="https://arxiv.org/abs/2401.08573" target="_blank">arXiv</a>]
                                    [<a href="https://wavesbench.github.io/">Website</a>]
                                    [<a href="https://github.com/umd-huang-lab/WAVES">Code</a>]
                                </td>
                            </tr>

                            <tr>
                                <td valign="top" width="95%" style="padding-bottom: 20px;">
                                    <papertitle>On the Possibilities of AI-Generated Text Detection</papertitle>
                                    <br>
                                    Souradip Chakraborty*,
                                    Amrit Singh Bedi*,
                                    <b>Sicheng Zhu</b>,
                                    Bang An,
                                    Dinesh Manocha,
                                    Furong Huang
                                    <br>
                                    <em>ICML 2024</em>
                                    [<a href="https://arxiv.org/abs/2304.04736" target="_blank">arXiv</a>]
                                </td>
                            </tr>

                        </tbody>
                    </table>

                    <!-- Publications Section -->
                    <heading style="display: block; margin-top: 30px; margin-bottom: 20px;"><b>Publications - Generalization</b></heading>
                    <table style="margin-top: 20px;" width="100%">
                        <tbody>

                            <tr>
                                <td valign="top" width="95%" style="padding-bottom: 20px;">
                                    <papertitle>More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes</papertitle>
                                    <br>
                                    Bang An*,
                                    <b>Sicheng Zhu*</b>,
                                    Michael-Andrei Panaitescu-Liess,
                                    Chaithanya Kumar Mummadi,
                                    Furong Huang
                                    <br>
                                    <em>ICLR 2024</em>
                                    [<a href="https://arxiv.org/abs/2308.01313" target="_blank">arXiv</a>]
                                    [<a href="https://github.com/umd-huang-lab/perceptionCLIP" target="_blank">Code</a>]
                                </td>
                            </tr>

                            <tr>
                                <td valign="top" width="95%" style="padding-bottom: 20px;">
                                    <papertitle>Learning Unforeseen Robustness from Out-of-distribution Data Using Equivariant Domain Translator</papertitle>
                                    <br>
                                    <b>Sicheng Zhu</b>,
                                    Bang An,
                                    Furong Huang,
                                    Sanghyun Hong
                                    <br>
                                    <em>ICML 2023</em>
                                    [<a href="https://proceedings.mlr.press/v202/zhu23a.html" target="_blank">Proceedings</a>]
                                    [<a href="https://github.com/schzhu/unforeseen-robustness" target="_blank">Code</a>]
                                </td>
                            </tr>

                            <tr>
                                <td valign="top" width="95%" style="padding-bottom: 20px;">
                                    <papertitle>Understanding the Generalization Benefit of Model Invariance from a Data Perspective</papertitle>
                                    <br>
                                    <b>Sicheng Zhu*</b>,
                                    Bang An*,
                                    Furong Huang
                                    <br>
                                    <em>NeurIPS 2021</em>
                                    [<a href="https://proceedings.neurips.cc/paper/2021/hash/2287c6b8641dd2d21ab050eb9ff795f3-Abstract.html" target="_blank">Proceedings</a>]
                                    [<a href="https://arxiv.org/abs/2111.05529" target="_blank">arXiv</a>]
                                    [<a href="https://github.com/bangann/understanding-invariance" target="_blank">Code</a>]
                                </td>
                            </tr>

                        </tbody>
                    </table>

                    <!-- Publications Section -->
                    <heading style="display: block; margin-top: 30px; margin-bottom: 20px;"><b>Publications - Adversarial robustness</b></heading>
                    <table style="margin-top: 20px;" width="100%">
                        <tbody>

                            <tr>
                                <td valign="top" width="95%" style="padding-bottom: 20px;">
                                    <papertitle>Learning Adversarially Robust Representations via Worst-Case Mutual Information Maximization</papertitle>
                                    <br>
                                    <b>Sicheng Zhu*</b>,
                                    Xiao Zhang*,
                                    David Evans
                                    <br>
                                    <em>ICML 2020</em>
                                    [<a href="https://proceedings.mlr.press/v119/zhu20e.html" target="_blank">Proceedings</a>]
                                    [<a href="https://arxiv.org/abs/2002.11798.pdf" target="_blank">arXiv</a>]
                                    [<a href="https://github.com/schzhu/learning-adversarially-robust-representations" target="_blank">Code</a>]
                                </td>
                            </tr>

                        </tbody>
                    </table>

                </td>
            </tr>
        </tbody>
    </table>

    <!-- Footer Section -->
    <table style="width:100%; padding-right:30px; padding-top:40px; border:0; border-spacing:10px; border-collapse:separate; margin: 0 auto;">
        <tbody>
            <tr>
                <td>
                    <p style="text-align:center; font-size:16px;">
                        <a href="https://jonbarron.info/" target="_blank">Website template credit</a>
                    </p>
                </td>
            </tr>
        </tbody>
    </table>
</body>
</html>
