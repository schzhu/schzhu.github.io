<!DOCTYPE html>
<!-- saved from url=(0083)file:///C:/Users/ZDZ/OneDrive/MyProjects/personal_website/website-master/index.html -->
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script type="text/javascript" async="" src="./index_files/analytics.js.download"></script>
    <script async="" src="./index_files/js"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'UA-7580334-2');
    </script>

    <title>Sicheng Zhu</title>

    <meta name="author" content="Sicheng Zhu">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="./index_files/stylesheet.css">
    <link rel="icon" type="image/png" href="./images/icon.png">
    <link rel="stylesheet" href="../../../../AppData/Local/Temp/stylesheet.css">
</head>

<body>
<table style="width:100%;max-width:900px;padding-top:20px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <p align="center" style="margin-bottom:-10px;">
                <name>Sicheng Zhu</name>
            </p>
            <p align="center" style="margin-bottom:-0px;">
                <span style="margin-right: 30px;">&#9993; sczhu[at]umd[dot]edu</span> 
                <a href="https://scholar.google.com/citations?hl=en&user=WdTVEcMAAAAJ" target="_blank">
                    <img src="images/google-scholar.svg" alt="Google Scholar Icon" style="width:20px; height:20px; vertical-align:middle;"> Google Scholar
                </a>
                <a href="https://twitter.com/sichengzhuml" target="_blank" style="margin-left: 30px;"> 
                    <img src="images/twitter-icon.svg" alt="Twitter Icon" style="width:20px; height:20px; vertical-align:middle;"> Twitter
                </a>
            </p>


            <img src="./images/sichengzhu_b.jpg" width="22%"
                 style="border-radius:10px; float: right; margin-left: 20px; margin-bottom: 20px;">

            <!--        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">-->
            <!--          <tbody><tr>-->
            <!--            <td width="74%" valign="top" align="justify">-->
            <p>
                I am a Ph.D. student in the <a href="https://www.cs.umd.edu/">Computer Science
                Department</a> at the <a href="http://www.umd.edu/">University of Maryland, College
                Park</a>, advised by Prof. <a href="http://furong-huang.com/">Furong Huang</a>.
            </p>
            <heading style="display: block; margin-top: 30px;"><b>Research Interest</b></heading>
            <p>
                My goal is to build <b>trustworthy machine learning</b> models.
            </p>
            <p>
                When you are sitting in a self-driving car controlled by such a machine learning
                model, you know it can recognize trucks because it can identify the wheels, body,
                and cab that make up the truck, and it can recognize the wheels because it notices
                contours, tire materials, and hubs (<b>interpretability</b>). It can identify trucks
                at various angles, lighting conditions, and even under adversarial stickers (<b>robustness</b>).
                It can also recognize a wide variety of trucks, from heavy trailers to Cybertrucks (<b>generalization</b>).
                Therefore, you can confidently hand over the steering wheel to it and take a nap on
                your way to work without worrying about it <a
                    href="https://www.forbes.com/sites/bradtempleton/2020/06/02/tesla-in-taiwan-crashes-directly-into-overturned-truck-ignores-pedestrian-with-autopilot-on/?sh=3d4ec39758e5">inexplicably
                crashing into an overturned white truck</a>.
            </p>
            <p>
                My approach to achieving this goal is by endowing machines with common sense about
                the physical world, with a current focus on modeling the symmetries of objects under
                various changes that could potentially reduce the learning complexity. For example,
                when applying angle transformations, material changes, or some pattern changes on a
                wheel in an image, it still appears as a wheel to humans and maintains its function.
                My current work aims at incorporating these symmetries into the model.
            </p>
            <heading style="display: block; margin-top: 30px;"><b>Bio</b></heading>
            <p>
                Previously, I was a visiting scholar at the <a href="https://www.virginia.edu/">University
                of Virginia</a> where I was fortunate to be advised by Prof. <a
                    href="http://www.cs.virginia.edu/~evans/">David Evans</a>. I received my M.E.
                from <a href="http://english.cas.cn/">Institute of Electronics, Chinese Academy of
                Sciences</a> and B.S. from <a href="http://en.uestc.edu.cn/">University of
                Electronic Science and Technology of China</a>.
            </p>

            <heading style="display: block; margin-top: 30px; margin-bottom: 20px;"><b>Preprints</b>
            </heading>

    <tr>
        <td valign="top" width="95%">
            <papertitle>Benchmarking the Robustness of Image Watermarks
            </papertitle>
            <br>
            Bang An, Mucong Ding, Tahseen Rabbani, Aakriti Agrawal, Yuancheng Xu, Chenghao Deng, 
            <b>Sicheng Zhu</b>, Abdirisak Mohamed, Yuxin Wen, Tom Goldstein, Furong Huang
            <br>
            <em>arXiv 2401.08573</em>
            <br>
            [<a href="https://arxiv.org/abs/2401.08573">arXiv</a>]
        </td>
    </tr>

    <tr style="display: block; margin-top: 20px;">
        <td valign="top" width="95%">
            <papertitle>AutoDAN: Interpretable Gradient-Based Adversarial Attacks on Large Language
                Models
            </papertitle>
            <br>
            <b>Sicheng Zhu</b>,
            Ruiyi Zhang,
            Bang An,
            Gang Wu,
            Joe Barrow,
            Zichao Wang,
            Furong Huang,
            Ani Nenkova,
            Tong Sun
            <br>
            <em>arXiv 2310.15140</em>
            <br>
            [<a href="https://arxiv.org/abs/2310.15140">arXiv</a>]
            [<a href="https://autodan-jailbreak.github.io/">Webpage</a>]
        </td>
    </tr>

    <tr style="display: block; margin-top: 20px;">
        <td valign="top" width="95%">
            <papertitle>On the Possibilities of AI-Generated Text Detection</papertitle>
            <br>
            Souradip Chakraborty*,
            Amrit Singh Bedi*,
            <b>Sicheng Zhu</b>,
            Bang An,
            Dinesh Manocha,
            Furong Huang
            <br>
            <em>arXiv 2304.04736</em>
            <br>
            [<a href="https://arxiv.org/abs/2304.04736">arXiv</a>]
        </td>
    </tr>

    <tr style="display: block; margin-top: 30px;">
        <td valign="top" width="95%">
            <heading style="display: block; margin-bottom: 20px;"><b>Publications</b></heading>
            <papertitle>More Context, Less Distraction: Visual Classification by Inferring and
                Conditioning on Contextual Attributes
            </papertitle>
            <br>
            Bang An*,
            <b>Sicheng Zhu*</b>,
            Michael-Andrei Panaitescu-Liess,
            Chaithanya Kumar Mummadi,
            Furong Huang
            <br>
            <em>ICLR 2024</em>
            <br>
            [<a href="https://arxiv.org/abs/2308.01313">arXiv</a>]
            [<a href="https://github.com/umd-huang-lab/perceptionCLIP">Code</a>]
        </td>
    </tr>

    <tr style="display: block; margin-top: 20px;">
        <td valign="top" width="95%">
            <papertitle>Like Oil and Water: Group Robustness Methods and Poisoning Defenses Don't Mix
            </papertitle>
            <br>
            Michael-Andrei Panaitescu-Liess,
            Yigitcan Kaya,
            <b>Sicheng Zhu</b>,
            Furong Huang,
            Tudor Dumitras
            <br>
            <em>ICLR 2024</em>
            <br>
            [<a href="https://openreview.net/forum?id=rM9VJPB20F">link</a>]
        </td>
    </tr>

    <tr style="display: block; margin-top: 20px;">
        <td valign="top" width="95%">
            <papertitle>Learning Unforeseen Robustness from Out-of-distribution Data Using
                Equivariant Domain Translator
            </papertitle>
            <br>
            <b>Sicheng Zhu</b>,
            Bang An,
            Furong Huang,
            Sanghyun Hong
            <br>
            <em>ICML 2023</em>
            <br>
            [<a href="https://proceedings.mlr.press/v202/zhu23a.html">Link</a>]
            [<a href="https://github.com/schzhu/unforeseen-robustness">Code</a>]
        </td>
    </tr>

    <tr style="display: block; margin-top: 20px;">
        <td valign="top" width="95%">
            <papertitle>Understanding the Generalization Benefit of Model Invariance from a Data
                Perspective
            </papertitle>
            <br>
            <b>Sicheng Zhu*</b>,
            Bang An*,
            Furong Huang
            <br>
            <em>NeurIPS 2021</em>
            <br>
            [<a href="https://proceedings.neurips.cc/paper/2021/hash/2287c6b8641dd2d21ab050eb9ff795f3-Abstract.html">Link</a>]
            [<a href="https://arxiv.org/abs/2111.05529">arXiv</a>]
            [<a href="https://github.com/bangann/understanding-invariance">Code</a>]
        </td>
    </tr>

    <tr style="display: block; margin-top: 20px;">
        <td valign="top" width="95%">
            <papertitle>Learning Adversarially Robust Representations via Worst-Case Mutual
                Information Maximization
            </papertitle>
            <br>
            <b>Sicheng Zhu*</b>,
            Xiao Zhang*,
            David Evans
            <br>
            <em>ICML 2020</em>
            <br>
            [<a href="https://proceedings.mlr.press/v119/zhu20e.html">Link</a>]
            [<a href="https://arxiv.org/abs/2002.11798.pdf">arXiv</a>]
            [<a href="https://github.com/schzhu/learning-adversarially-robust-representations">Code</a>]
        </td>
    </tr>

    </tbody>
</table>

<table style="width:100%;padding-right:30px;padding-top:40px;border:0px;border-spacing:10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr>
        <td style="padding:0px">
            <br>
            <p style="text-align:center;font-size:16px;">
                <br>
                <a href="https://jonbarron.info/">Website template credit</a>
            </p>
        </td>
    </tr>
    </tbody>
</table>


</body>
</html>
